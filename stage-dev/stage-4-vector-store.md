# Stage 4: Vector Store & Embeddings

## ç›®æ ‡

ä¸ºæŠ€èƒ½åˆ›å»ºå‘é‡åµŒå…¥ï¼Œæ”¯æŒè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢ã€‚

## è¾“å…¥/è¾“å‡º

- **è¾“å…¥**: `data/skills.json` (æ¥è‡ª Stage 2)
- **è¾“å‡º**: ChromaDB å‘é‡ç´¢å¼•

## å‰ç½®æ¡ä»¶

- Stage 2 å®Œæˆ
- å¯é€‰: OpenAI API Key (ä½¿ç”¨ OpenAI embeddings)

---

## ä»»åŠ¡åˆ†è§£

### 4.1 Embedding æ¨¡å‹é€‰æ‹©

```python
# src/vector_store/embeddings.py

from sentence_transformers import SentenceTransformer
from openai import OpenAI
import os
from typing import List
import numpy as np

class EmbeddingModel:
    """Embedding æ¨¡å‹æŠ½è±¡åŸºç±»"""
    def encode(self, texts: List[str]) -> np.ndarray:
        raise NotImplementedError

class LocalEmbedding(EmbeddingModel):
    """æœ¬åœ° sentence-transformers æ¨¡å‹"""
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)

    def encode(self, texts: List[str]) -> np.ndarray:
        return self.model.encode(texts, show_progress_bar=True)

class OpenAIEmbedding(EmbeddingModel):
    """OpenAI embedding API"""
    def __init__(self, model: str = "text-embedding-3-small"):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = model

    def encode(self, texts: List[str]) -> np.ndarray:
        response = self.client.embeddings.create(
            model=self.model,
            input=texts
        )
        return np.array([e.embedding for e in response.data])

def get_embedding_model(use_openai: bool = False) -> EmbeddingModel:
    """è·å– embedding æ¨¡å‹"""
    if use_openai:
        return OpenAIEmbedding()
    return LocalEmbedding()
```

### 4.2 ChromaDB å‘é‡å­˜å‚¨

```python
# src/vector_store/store.py

import chromadb
from chromadb.config import Settings
import json
from typing import List, Tuple

class SkillVectorStore:
    def __init__(self, persist_dir: str = "data/chroma"):
        self.client = chromadb.Client(Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory=persist_dir
        ))
        self.collection = self.client.get_or_create_collection(
            name="skills",
            metadata={"hnsw:space": "cosine"}
        )

    def add_skills(self, skills: List[dict], embeddings: List[List[float]]):
        """
        æ·»åŠ æŠ€èƒ½åˆ°å‘é‡å­˜å‚¨

        Args:
            skills: æŠ€èƒ½åˆ—è¡¨
            embeddings: å¯¹åº”çš„ embedding å‘é‡
        """
        ids = [s["name"] for s in skills]
        documents = [self._skill_to_document(s) for s in skills]
        metadatas = [{"category": s["category"], "aliases": ",".join(s.get("aliases", []))} for s in skills]

        self.collection.add(
            ids=ids,
            documents=documents,
            embeddings=embeddings,
            metadatas=metadatas
        )

    def _skill_to_document(self, skill: dict) -> str:
        """å°†æŠ€èƒ½è½¬æ¢ä¸ºç”¨äº embedding çš„æ–‡æœ¬"""
        aliases = skill.get("aliases", [])
        alias_str = f". Also known as: {', '.join(aliases)}" if aliases else ""
        return f"{skill['name']}{alias_str}. Category: {skill['category']}"

    def search(self, query: str, query_embedding: List[float], top_k: int = 10) -> List[Tuple[str, float]]:
        """
        æœç´¢æœ€ç›¸å…³çš„æŠ€èƒ½

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            query_embedding: æŸ¥è¯¢çš„ embedding
            top_k: è¿”å›æ•°é‡

        Returns:
            List[(skill_name, similarity_score)]
        """
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["distances", "metadatas"]
        )

        skills = []
        for i, skill_id in enumerate(results["ids"][0]):
            # ChromaDB è¿”å›è·ç¦»ï¼Œè½¬æ¢ä¸ºç›¸ä¼¼åº¦
            distance = results["distances"][0][i]
            similarity = 1 - distance  # cosine distance to similarity
            skills.append((skill_id, similarity))

        return skills

    def persist(self):
        """æŒä¹…åŒ–å­˜å‚¨"""
        self.client.persist()

    def clear(self):
        """æ¸…ç©ºé›†åˆ"""
        self.client.delete_collection("skills")
        self.collection = self.client.create_collection(
            name="skills",
            metadata={"hnsw:space": "cosine"}
        )
```

### 4.3 ç´¢å¼•æ„å»ºç®¡é“

```python
# src/vector_store/indexer.py

import json
from .embeddings import get_embedding_model
from .store import SkillVectorStore

class VectorIndexer:
    def __init__(self, use_openai: bool = False, persist_dir: str = "data/chroma"):
        self.embedding_model = get_embedding_model(use_openai)
        self.store = SkillVectorStore(persist_dir)

    def build_index(self, skills_path: str):
        """
        ä¸ºæŠ€èƒ½æ„å»ºå‘é‡ç´¢å¼•

        Args:
            skills_path: skills.json è·¯å¾„
        """
        # åŠ è½½æŠ€èƒ½
        with open(skills_path) as f:
            skills = json.load(f)

        print(f"Building index for {len(skills)} skills...")

        # ç”Ÿæˆæ–‡æœ¬
        texts = [self._skill_to_text(s) for s in skills]

        # ç”Ÿæˆ embeddings
        embeddings = self.embedding_model.encode(texts)

        # å­˜å…¥å‘é‡åº“
        self.store.clear()
        self.store.add_skills(skills, embeddings.tolist())
        self.store.persist()

        print(f"âœ“ Index built and persisted")

    def _skill_to_text(self, skill: dict) -> str:
        """å°†æŠ€èƒ½è½¬æ¢ä¸º embedding æ–‡æœ¬"""
        aliases = skill.get("aliases", [])
        alias_str = f". Also known as: {', '.join(aliases)}" if aliases else ""
        return f"{skill['name']}{alias_str}. Category: {skill['category']}"

    def search(self, query: str, top_k: int = 10) -> List[Tuple[str, float]]:
        """
        æœç´¢ç›¸å…³æŠ€èƒ½

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡

        Returns:
            List[(skill_name, similarity_score)]
        """
        # ç”ŸæˆæŸ¥è¯¢ embedding
        query_embedding = self.embedding_model.encode([query])[0]

        # æœç´¢
        return self.store.search(query, query_embedding.tolist(), top_k)
```

### 4.4 ä¸»è„šæœ¬

```python
# scripts/build_vector_index.py

import argparse
from src.vector_store.indexer import VectorIndexer

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--skills", default="data/skills.json")
    parser.add_argument("--persist-dir", default="data/chroma")
    parser.add_argument("--use-openai", action="store_true")
    args = parser.parse_args()

    indexer = VectorIndexer(
        use_openai=args.use_openai,
        persist_dir=args.persist_dir
    )
    indexer.build_index(args.skills)

    # æµ‹è¯•æœç´¢
    print("\nğŸ” Test search: 'machine learning'")
    results = indexer.search("machine learning", top_k=5)
    for skill, score in results:
        print(f"   {skill}: {score:.3f}")

if __name__ == "__main__":
    main()
```

### 4.5 æœç´¢æœåŠ¡

```python
# src/vector_store/search_service.py

from .indexer import VectorIndexer
from typing import List

class SkillSearchService:
    """æŠ€èƒ½æœç´¢æœåŠ¡ï¼Œä¾› RAG ç³»ç»Ÿè°ƒç”¨"""

    def __init__(self, persist_dir: str = "data/chroma", use_openai: bool = False):
        self.indexer = VectorIndexer(use_openai, persist_dir)

    def find_related_skills(self, query: str, top_k: int = 10) -> List[str]:
        """
        æŸ¥æ‰¾ä¸æŸ¥è¯¢ç›¸å…³çš„æŠ€èƒ½

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            top_k: è¿”å›æ•°é‡

        Returns:
            List[str]: æŠ€èƒ½åç§°åˆ—è¡¨
        """
        results = self.indexer.search(query, top_k)
        return [skill for skill, score in results if score > 0.3]  # è¿‡æ»¤ä½ç›¸ä¼¼åº¦

    def find_skills_with_scores(self, query: str, top_k: int = 10) -> List[dict]:
        """
        æŸ¥æ‰¾ç›¸å…³æŠ€èƒ½åŠå…¶åˆ†æ•°

        Returns:
            List[dict]: [{"name": "Python", "score": 0.85}, ...]
        """
        results = self.indexer.search(query, top_k)
        return [{"name": skill, "score": score} for skill, score in results]
```

---

## æ–‡ä»¶ç»“æ„

```
stage4/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ vector_store/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ embeddings.py
â”‚       â”œâ”€â”€ store.py
â”‚       â”œâ”€â”€ indexer.py
â”‚       â””â”€â”€ search_service.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ build_vector_index.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ chroma/           # ChromaDB æŒä¹…åŒ–ç›®å½•
â””â”€â”€ tests/
    â””â”€â”€ test_vector_store.py
```

---

## éªŒæ”¶æ ‡å‡†

- [ ] ChromaDB æˆåŠŸå­˜å‚¨æ‰€æœ‰æŠ€èƒ½ embeddings
- [ ] æœç´¢ "machine learning" è¿”å› ML ç›¸å…³æŠ€èƒ½
- [ ] æœç´¢ "Python" è¿”å›ç¼–ç¨‹ç›¸å…³æŠ€èƒ½
- [ ] æœç´¢ "policy" è¿”å›æ”¿ç­–ç›¸å…³æŠ€èƒ½
- [ ] ç›¸ä¼¼åº¦åˆ†æ•°åˆç† (ç›¸å…³æŠ€èƒ½ > 0.5)
- [ ] ç´¢å¼•å¯æŒä¹…åŒ–å’Œé‡æ–°åŠ è½½

---

## ä¾èµ–é¡¹

```txt
chromadb
sentence-transformers
# å¯é€‰: openai (å¦‚ä½¿ç”¨ OpenAI embeddings)
```

---

## æµ‹è¯•ç”¨ä¾‹

```python
# tests/test_vector_store.py

def test_skill_search():
    service = SkillSearchService()

    # æµ‹è¯• 1: ML ç›¸å…³
    results = service.find_related_skills("deep learning neural networks")
    assert "Machine Learning" in results or "Deep Learning" in results

    # æµ‹è¯• 2: ç¼–ç¨‹ç›¸å…³
    results = service.find_related_skills("Python coding")
    assert "Python" in results

    # æµ‹è¯• 3: æ”¿ç­–ç›¸å…³
    results = service.find_related_skills("government policy analysis")
    assert "Public Policy" in results
```
